{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_dataset(dataset, train_perc=0.8,test_perc = 0.2):\n",
    "    np.random.shuffle(dataset)\n",
    "    data_len = len(dataset)\n",
    "    train_index = int(data_len*train_perc) # last index from the dataset array that will go into training\n",
    "    \n",
    "    train = dataset[:train_index,:]  \n",
    "    test = dataset[train_index:,:] \n",
    "    return (train, test)\n",
    "\n",
    "def sigmoid(activation):\n",
    "    return 1.0 / (1.0 + np.exp(-activation))\n",
    "    \n",
    "def compute_loss(prediction, actual):\n",
    "    #return -sum(actual*log(prediction))\n",
    "    return 0.5*np.sum((actual.T-prediction)*(actual.T-prediction))\n",
    "\n",
    "def back_prop(train_X,W1,W2,layer1_output,layer2_output,actual_output):\n",
    "    #find error in output unit\n",
    "    difference = actual_output.T - layer2_output    \n",
    "    delta_output = layer2_output*(1-layer2_output)*difference\n",
    "    delta_hidden = layer1_output*(1-layer1_output)*W2.T.dot(delta_output)\n",
    "    deltaW2 = lr*(delta_output.dot(layer1_output.T)/n_train) \n",
    "    deltaW1 = lr*(delta_hidden.dot(train_X)/n_train) \n",
    "    \n",
    "    return (deltaW1,deltaW2)\n",
    "    \n",
    "def train_network(train_X, train_y):\n",
    "    n_input = train_X.shape[1]  # the number of columns in the training data\n",
    "    W1=np.random.random((n_hidden,n_input))\n",
    "    W2=np.random.random((num_classes,n_hidden ))\n",
    "    for epoch in range(n_epoch):\n",
    "        layer1_output = sigmoid(W1.dot(train_X.T))\n",
    "        layer2_output = sigmoid(W2.dot(layer1_output))\n",
    "        \n",
    "        (deltaW1,deltaW2)= back_prop(train_X,W1,W2,layer1_output,layer2_output,train_y)\n",
    "        print(deltaW1[:5])\n",
    "        W2 = W2+deltaW2\n",
    "        W1 = W1+deltaW1\n",
    "        if epoch%1000 == 0:\n",
    "            loss = compute_loss(layer2_output,train_y)\n",
    "            print(str.format('Loss in {0}th epoch is {1}',epoch,loss))\n",
    "        \n",
    "            \n",
    "    return (W1,W2)\n",
    "\n",
    "def evaluate(test_X,test_y,params):\n",
    "    (W1,W2) = params\n",
    "    layer1_output = sigmoid(W1.dot(test_X.T))\n",
    "    final = sigmoid(W2.dot(layer1_output))\n",
    "    \n",
    "    prediction = final.argmax(axis=0)    \n",
    "    return np.sum(prediction==test_y)/len(test_y)    \n",
    "\n",
    "def convert_to_OH(data,num_classes):\n",
    "    #create an array to store the one hot vectors\n",
    "    one_hot = np.zeros((len(data),num_classes))\n",
    "    one_hot[np.arange(len(data)),data] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "# load and prepare data\n",
    "#filename = 'seeds_dataset.csv'\n",
    "filename = '/home/ishaan/Downloads/diabetes.csv'\n",
    "df = pd.read_csv(filename,dtype=np.float64)\n",
    "dataset = np.array(df)\n",
    "\n",
    "#normalize data\n",
    "min_data = dataset.min(axis = 0)\n",
    "max_data = dataset.max(axis = 0)\n",
    "\n",
    "#normalize all fields except the last column(class)\n",
    "dataset[:,0:-1] = (dataset[:,0:-1] - min_data[0:-1])/(max_data[0:-1] - min_data[0:-1])\n",
    "(train, test) = split_dataset(dataset)\n",
    "print(train[:5,:-1])\n",
    "#train = dataset \n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "\n",
    "# evaluate algorithm\n",
    "lr = 0.8\n",
    "n_epoch =15000\n",
    "\n",
    "#determine the number of classes\n",
    "num_classes = len(np.unique(dataset[:,-1]))\n",
    "train_one_hot = convert_to_OH(train[:,-1].astype(int),num_classes)\n",
    "\n",
    "n_hidden = 15\n",
    "\n",
    "params = train_network(train[:,:-1],train_one_hot) \n",
    "accuracy = evaluate(test[:,:-1],test[:,-1],params)*100\n",
    "print('Mean Accuracy: %.3f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
